## week 3

### 1.28
When trying to get some methods to solve RCA from AI like chatGPT and Gemini, I always get methods like GCN and random forest, but based on my understanding, they fail to reach high performances with our data. Today, I finally get the reason. To most AI, RCA means finding the abnormal condition when some alarms show up, but for our goal, we want to find the connection among the alarms without any other information. After talking with my supervisor, we get two ways at present: 1. using the method that I had come up with, with GCN, 2. trying to get other information, like temperature, software version, hardware name, etc. to change our task from alarm-level RCA to system-level RCA, the kind of problem that most AI consider.

I quickly go through random forest, and have some ideas in mind. After getting some data, I would like to give it a try. Also, some rules will be given for my former method, which approximately computes correlation between alarms by the frequecy of appearance of the alarm conbination.

### 1.29
For the entire day I've been trying to realize one idea that I just came up with: building an alarm tree, or alarm forest based on the correlation method that I have built. It checks every possible root cause and connects them to the alarms generated by them. Meanwhile, after understanding my algorithm, my supervisor provides some valuable suggestions, along with one huge concept: instead of building the general correlation, we can build one correlation matrix for each network element (NE), and another for all the NEs. The key idea is that NEs only communicate through TPs, and by leveraging this property, this method helps let attributing each node a feature achievable.

There still exist some problems. I have not figured out wether to compute for one time or multiple times. Besides, the method of computing correlation needs to be improved.

### 2.2
After some discussions, we had found that constructing matrixes for all the ne and the entire system was impossible. For one province, it could contains southands of NEs, which means that even the matrix with only ptp contains up to 10000000000 parameters. So I modified my algorithm again to get it back to the original version, but with some changes. With the same training process, when predicting, I construct some matrixes for all the alarms for calculation. By this, we leverage the possible rules generated by history data for general cases, and get back to the reality to see whether the relations could happen.

### 2.3
The basic algorithms are constructed, what bothered me today was nebula, a graph database. We try to use nebula to store and use our data, so little preparation did we have made, and there's no function that we can use directly but crafting them ourselves. Unfortunately, I have little knowledge in database and SQL languages, so it takes some time for me to construct the functions I want, but with the help of my supervisor and AI, I finally made it. There are still some problems in my algorithm, and I'm ready to solve them as soon as possible tomorrow.